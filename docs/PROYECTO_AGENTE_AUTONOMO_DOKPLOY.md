# Sistema de Agente AutÃ³nomo para GestiÃ³n de Infraestructura Dokploy
## Proyecto: InfraGuardian AI - Dokploy Edition

> **Especialmente diseÃ±ado para infraestructura 100% Dokploy + Docker Compose**
>
> **ğŸ†• Powered by GPT-OSS 20B (OpenAI Open Source) - 100% Local, $0/mes**

### ğŸ¯ Highlights del Proyecto

- ğŸ¤– **GPT-OSS 20B**: Primer modelo open source de OpenAI (Apache 2.0)
- ğŸ’° **Costo Operacional**: $0/mes (todo local en RTX 5090)
- ğŸ”’ **Privacidad Total**: Cero datos enviados a terceros
- âš¡ **Function Calling**: OpenAI-grade, superior a Llama/Qwen
- ğŸ›ï¸ **Reasoning Ajustable**: Low/Medium/High segÃºn criticidad
- ğŸ“¦ **16GB VRAM**: Cabe perfecto en tu RTX 5090
- ğŸš€ **6 Semanas**: Plan de implementaciÃ³n completo

---

## ğŸ“‹ Ãndice

1. [Contexto de Infraestructura](#contexto-de-infraestructura)
2. [VisiÃ³n General](#visiÃ³n-general)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [IntegraciÃ³n con Dokploy](#integraciÃ³n-con-dokploy)
5. [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
6. [GPT-OSS 20B: El Cerebro del Agente](#gpt-oss-20b-el-cerebro-del-agente)
7. [Componentes Principales](#componentes-principales)
8. [Requerimientos](#requerimientos)
9. [Plan de ImplementaciÃ³n](#plan-de-implementaciÃ³n)
10. [Casos de Uso Dokploy](#casos-de-uso-dokploy)
11. [Estimaciones](#estimaciones)

---

## ğŸ¢ Contexto de Infraestructura

### Stack Actual

Tu infraestructura completa corre sobre:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DOKPLOY (Servidor VPS)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Docker Compose Projects      â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â”‚  â€¢ Granada Shariff             â”‚    â”‚
â”‚  â”‚    - frontend (Next.js)        â”‚    â”‚
â”‚  â”‚    - api (FastAPI)             â”‚    â”‚
â”‚  â”‚    - postgres                  â”‚    â”‚
â”‚  â”‚    - redis                     â”‚    â”‚
â”‚  â”‚    - celery                    â”‚    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â”‚  â€¢ SaaS RAG                    â”‚    â”‚
â”‚  â”‚    - saas-rag-fastapi          â”‚    â”‚
â”‚  â”‚    - frontend (Next.js)        â”‚    â”‚
â”‚  â”‚    - postgres                  â”‚    â”‚
â”‚  â”‚    - redis                     â”‚    â”‚
â”‚  â”‚    - mongodb                   â”‚    â”‚
â”‚  â”‚    - weaviate                  â”‚    â”‚
â”‚  â”‚    - voicechat-api             â”‚    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â”‚  â€¢ MCP Servers                 â”‚    â”‚
â”‚  â”‚    - mcp-server (FastAPI)      â”‚    â”‚
â”‚  â”‚    - postgres                  â”‚    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â”‚  â€¢ Configs Servidor            â”‚    â”‚
â”‚  â”‚    - registry                  â”‚    â”‚
â”‚  â”‚    - minio                     â”‚    â”‚
â”‚  â”‚    - rustdesk                  â”‚    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â”‚  â€¢ YoReparo                    â”‚    â”‚
â”‚  â”‚    - frontend                  â”‚    â”‚
â”‚  â”‚    - backend                   â”‚    â”‚
â”‚  â”‚    - postgres                  â”‚    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â”‚  â€¢ Random Test                 â”‚    â”‚
â”‚  â”‚    - n8n                       â”‚    â”‚
â”‚  â”‚                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚  GestiÃ³n:                               â”‚
â”‚  â€¢ Dokploy API                          â”‚
â”‚  â€¢ Traefik (reverse proxy)              â”‚
â”‚  â€¢ Docker Engine                        â”‚
â”‚  â€¢ Networking automÃ¡tico                â”‚
â”‚  â€¢ SSL/TLS automÃ¡tico                   â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ventajas de Esta Arquitectura

1. **CentralizaciÃ³n Total**: Todo gestionado desde Dokploy
2. **API Unificada**: 259 endpoints para control completo
3. **Docker Nativo**: Todas las operaciones son Docker-based
4. **Auto-configuraciÃ³n**: Traefik, SSL, networking automÃ¡tico
5. **Compose-First**: Todos los servicios definidos en docker-compose.yml

### Implicaciones para el Agente

**SIMPLIFICACIÃ“N:**
- âŒ No necesitas SSH remoto a mÃºltiples servidores
- âŒ No necesitas mÃºltiples estrategias de deployment
- âŒ No necesitas gestiÃ³n manual de Kubernetes/VMs
- âœ… **TODO** se hace vÃ­a Dokploy API + Docker API
- âœ… Foco 100% en Compose/Containers
- âœ… Menor superficie de ataque

---

## ğŸ¯ VisiÃ³n General

**InfraGuardian AI - Dokploy Edition** es un agente autÃ³nomo especializado en infraestructura Dokploy, que entiende profundamente:

- Docker Compose services
- Dokploy projects y environments
- Container lifecycle (Traefik, health checks, etc.)
- Deployment workflows vÃ­a Dokploy
- Logs y mÃ©tricas de containers

### Propuesta de Valor EspecÃ­fica

- **GestiÃ³n de Compose**: Entiende relaciones entre servicios (postgresâ†’apiâ†’frontend)
- **Rollback Inteligente**: Usa Dokploy deployment history
- **Health Checks**: Monitorea health checks de Traefik + Docker
- **Logs Centralizados**: Analiza logs de todos los containers vÃ­a Docker API
- **Auto-healing**: Restart, redeploy, rollback automÃ¡tico

---

## ğŸ—ï¸ Arquitectura del Sistema

### Arquitectura EspecÃ­fica Dokploy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TELEGRAM BOT (Interfaz)                     â”‚
â”‚  - Comandos: /status, /restart, /logs, /deploy                 â”‚
â”‚  - ConversaciÃ³n: "Â¿Por quÃ© estÃ¡ caÃ­do Granada?"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LANGGRAPH AGENT CORE                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Dokploy-Aware Agent                         â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  States:                                                 â”‚  â”‚
â”‚  â”‚  1. MONITOR â†’ Detecta anomalÃ­as en containers          â”‚  â”‚
â”‚  â”‚  2. ANALYZE â†’ Analiza logs + mÃ©tricas Docker           â”‚  â”‚
â”‚  â”‚  3. PLAN    â†’ Decide acciÃ³n (restart/redeploy/scale)   â”‚  â”‚
â”‚  â”‚  4. EXECUTE â†’ Ejecuta vÃ­a Dokploy API                  â”‚  â”‚
â”‚  â”‚  5. VERIFY  â†’ Valida health checks                     â”‚  â”‚
â”‚  â”‚  6. LEARN   â†’ Actualiza knowledge base                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚GPT-OSS 20B      â”‚    â”‚   Knowledge Base               â”‚    â”‚
â”‚  â”‚ (Local/RTX5090) â”‚    â”‚   - Compose patterns           â”‚    â”‚
â”‚  â”‚  - Entiende     â”‚    â”‚   - Dokploy API calls          â”‚    â”‚
â”‚  â”‚    Compose      â”‚    â”‚   - Container dependencies     â”‚    â”‚
â”‚  â”‚  - Relaciones   â”‚    â”‚   - Runbooks especÃ­ficos       â”‚    â”‚
â”‚  â”‚    servicios    â”‚    â”‚   - ChromaDB (local)           â”‚    â”‚
â”‚  â”‚  - Function     â”‚    â”‚                                â”‚    â”‚
â”‚  â”‚    calling      â”‚    â”‚                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HERRAMIENTAS (Tools)                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         DOKPLOY API CLIENT (Principal)                  â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Projects:                                              â”‚   â”‚
â”‚  â”‚  - project.all()                                        â”‚   â”‚
â”‚  â”‚  - project.one(projectId)                               â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Compose:                                               â”‚   â”‚
â”‚  â”‚  - compose.one(composeId)                               â”‚   â”‚
â”‚  â”‚  - compose.deploy(composeId)                            â”‚   â”‚
â”‚  â”‚  - compose.redeploy(composeId)                          â”‚   â”‚
â”‚  â”‚  - compose.start(composeId)                             â”‚   â”‚
â”‚  â”‚  - compose.stop(composeId)                              â”‚   â”‚
â”‚  â”‚  - compose.loadServices(composeId)                      â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Domains:                                               â”‚   â”‚
â”‚  â”‚  - domain.byComposeId(composeId)                        â”‚   â”‚
â”‚  â”‚  - domain.validateDomain(domain)                        â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Deployments:                                           â”‚   â”‚
â”‚  â”‚  - deployment.all()                                     â”‚   â”‚
â”‚  â”‚  - deployment.allByCompose(composeId)                   â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  Databases:                                             â”‚   â”‚
â”‚  â”‚  - postgres.one(postgresId)                             â”‚   â”‚
â”‚  â”‚  - postgres.restart(postgresId)                         â”‚   â”‚
â”‚  â”‚  - mysql.one(mysqlId)                                   â”‚   â”‚
â”‚  â”‚  - mongo.one(mongoId)                                   â”‚   â”‚
â”‚  â”‚  - redis.one(redisId)                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         DOCKER API CLIENT (Complementario)              â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  - docker.containers.list()                             â”‚   â”‚
â”‚  â”‚  - docker.containers.get(id).logs()                     â”‚   â”‚
â”‚  â”‚  - docker.containers.get(id).stats()                    â”‚   â”‚
â”‚  â”‚  - docker.containers.get(id).restart()                  â”‚   â”‚
â”‚  â”‚  - docker.images.prune()                                â”‚   â”‚
â”‚  â”‚  - docker.volumes.prune()                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         ANALISIS DE LOGS                                â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  - parse_container_logs(container_id)                   â”‚   â”‚
â”‚  â”‚  - search_error_patterns(logs)                          â”‚   â”‚
â”‚  â”‚  - extract_stack_traces(logs)                           â”‚   â”‚
â”‚  â”‚  - correlate_service_errors(compose_services)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITOREO                                    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Docker Stats    â”‚    â”‚  Dokploy Health  â”‚                 â”‚
â”‚  â”‚  - CPU/RAM       â”‚    â”‚  - Health checks â”‚                 â”‚
â”‚  â”‚  - Network I/O   â”‚    â”‚  - Deploy status â”‚                 â”‚
â”‚  â”‚  - Disk I/O      â”‚    â”‚  - Domain status â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Uptime Kuma     â”‚    â”‚  Custom Metrics  â”‚                 â”‚
â”‚  â”‚  - Availability  â”‚    â”‚  - API latency   â”‚                 â”‚
â”‚  â”‚  - Response time â”‚    â”‚  - Queue depth   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— IntegraciÃ³n con Dokploy

### API de Dokploy: Tu Ãšnica Interfaz

Tienes acceso a **259 endpoints**. Los mÃ¡s relevantes para el agente:

#### Compose Management (23 endpoints)

```python
# El agente usarÃ¡ principalmente estos:

# InformaciÃ³n
compose.one(composeId)              # Obtener info completa
compose.loadServices(composeId)     # Listar servicios del compose

# Lifecycle
compose.deploy(composeId)           # Deploy from scratch
compose.redeploy(composeId)         # Redeploy
compose.start(composeId)            # Start todos los servicios
compose.stop(composeId)             # Stop todos los servicios

# Troubleshooting
compose.one(composeId).env          # Ver variables de entorno
compose.one(composeId).composeFile  # Ver docker-compose.yml
deployment.allByCompose(composeId)  # Ver historial de deploys

# Rollback
# Dokploy guarda historial, el agente puede:
# 1. Ver deployment anterior exitoso
# 2. Trigger redeploy con ese deployment

# Domains
domain.byComposeId(composeId)       # Ver dominios configurados
domain.validateDomain(domain)       # Validar DNS
```

#### Docker API Integration

```python
# Para mÃ©tricas y logs detallados
import docker

client = docker.from_env()

# Obtener containers de un compose
# Dokploy nombra containers: {projectName}-{serviceName}-{hash}
containers = client.containers.list(
    filters={
        "label": f"com.docker.compose.project={project_name}"
    }
)

# Para cada container:
container.stats(stream=False)  # CPU, RAM, Network, Disk
container.logs(tail=1000)      # Ãšltimas 1000 lÃ­neas
container.top()                # Procesos running
container.exec_run("df -h")    # Comandos dentro del container
```

### Ejemplo: Granada Shariff Project

Tu proyecto Granada Shariff tiene:

```yaml
services:
  frontend:
    - Port: 3000
    - Domain: granada.sphyrnasolutions.com
    - Health check: HTTP

  api:
    - Port: 8000
    - Domain: granada.back.sphyrnasolutions.com
    - Depends on: postgres, redis

  postgres:
    - Internal: No domain pÃºblico
    - Volume: Persistent data

  redis:
    - Internal: No domain pÃºblico

  celery:
    - Background worker
    - Depends on: redis, postgres
```

**El agente entiende estas relaciones:**

```python
# Si "frontend" estÃ¡ caÃ­do:
# 1. Check frontend container
# 2. Check si API estÃ¡ up (frontend depende de API)
# 3. Check postgres/redis (API depende de ellos)
# 4. Analizar logs en orden inverso de dependencia

# Si "postgres" estÃ¡ lento:
# 1. Afecta a: API, Celery
# 2. Indirectamente afecta: Frontend
# 3. Priorizar arreglo de postgres (cascada de efectos)
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico Optimizado

### Backend Core

```python
# Framework
fastapi==0.109.0
uvicorn[standard]==0.27.0

# LangChain Stack
langchain==0.1.5
langgraph==0.0.20
langchain-ollama==0.0.1       # Para GPT-OSS 20B local

# Dokploy Integration
aiohttp==3.9.1                # Async HTTP para Dokploy API
pydantic==2.5.0               # ValidaciÃ³n de datos API

# Docker Integration
docker==7.0.0                 # Docker Python SDK
docker-compose==1.29.2        # Parse docker-compose.yml

# Vector DB
chromadb==0.4.22              # Local, gratuito

# Telegram
python-telegram-bot==20.7

# Database
psycopg2-binary==2.9.9        # PostgreSQL
redis==5.0.1                  # Redis

# Utils
pyyaml==6.0.1                 # Parse YAML (runbooks + composes)
python-dotenv==1.0.0
```

### Herramientas EspecÃ­ficas Dokploy

```python
# src/integrations/dokploy_client.py
class DokployClient:
    """Cliente especializado para Dokploy API"""

    base_url = "https://settings.sphyrnasolutions.com/api"
    api_key = os.getenv("DOKPLOY_API_KEY")

    async def get_all_projects(self):
        """GET /project.all"""
        return await self._request("GET", "/project.all")

    async def get_compose_services(self, compose_id: str):
        """GET /compose.loadServices"""
        return await self._request("GET", "/compose.loadServices",
                                   params={"composeId": compose_id})

    async def deploy_compose(self, compose_id: str):
        """POST /compose.deploy"""
        return await self._request("POST", "/compose.deploy",
                                   json={"composeId": compose_id})

    async def get_deployment_history(self, compose_id: str):
        """GET /deployment.allByCompose"""
        return await self._request("GET", "/deployment.allByCompose",
                                   params={"composeId": compose_id})

# src/integrations/docker_client.py
class DockerComposeAnalyzer:
    """Analiza docker-compose.yml y containers"""

    def __init__(self):
        self.docker = docker.from_env()

    def get_compose_containers(self, project_name: str):
        """Obtener todos los containers de un compose"""
        return self.docker.containers.list(
            filters={
                "label": f"com.docker.compose.project={project_name}"
            }
        )

    def analyze_service_dependencies(self, compose_file: str):
        """Parse docker-compose.yml y extraer dependencias"""
        compose_data = yaml.safe_load(compose_file)
        services = compose_data.get("services", {})

        deps = {}
        for service_name, service_config in services.items():
            deps[service_name] = {
                "depends_on": service_config.get("depends_on", []),
                "links": service_config.get("links", []),
                "volumes_from": service_config.get("volumes_from", [])
            }
        return deps

    def get_service_health(self, container_id: str):
        """Health check de un servicio"""
        container = self.docker.containers.get(container_id)
        return {
            "status": container.status,
            "health": container.attrs.get("State", {}).get("Health", {}),
            "stats": container.stats(stream=False)
        }
```

---

## ğŸ¤– GPT-OSS 20B: El Cerebro del Agente

### Por QuÃ© GPT-OSS 20B

En agosto 2025, OpenAI lanzÃ³ **GPT-OSS** (20B y 120B) bajo licencia Apache 2.0, su primer modelo open source desde GPT-2. Para este proyecto, GPT-OSS 20B es la opciÃ³n ideal:

#### Especificaciones TÃ©cnicas

```
Modelo: gpt-oss-20b
Arquitectura: Mixture of Experts (MoE)
ParÃ¡metros totales: 21B
ParÃ¡metros activos: 3.6B (solo 17% activo por inferencia)
CuantizaciÃ³n: MXFP4 nativa
VRAM requerida: 16GB (perfecto para RTX 5090)
Rendimiento: Similar a o3-mini de OpenAI
Licencia: Apache 2.0 (uso comercial libre)
```

#### Capacidades Clave para el Agente

âœ… **Function Calling Nativo**: OpenAI-grade, superior a Llama/Qwen
âœ… **Reasoning Ajustable**: Low/Medium/High segÃºn necesidad
âœ… **Chain-of-Thought Visible**: Para debugging de decisiones
âœ… **Web Browsing**: Capacidad integrada
âœ… **Python Execution**: Puede ejecutar cÃ³digo
âœ… **Structured Outputs**: JSON schemas nativos
âœ… **Fine-tunable**: Especializable para tu infraestructura

#### ConfiguraciÃ³n de Reasoning Effort

```python
from langchain_ollama import ChatOllama

# Para monitoreo rutinario (rÃ¡pido)
llm_fast = ChatOllama(
    model="openai/gpt-oss-20b",
    temperature=0.3,
    model_kwargs={"reasoning_effort": "low"}  # ~1-2s
)

# Para diagnÃ³sticos normales (balanceado)
llm_normal = ChatOllama(
    model="openai/gpt-oss-20b",
    temperature=0.5,
    model_kwargs={"reasoning_effort": "medium"}  # ~2-3s
)

# Para anÃ¡lisis complejos (profundo)
llm_deep = ChatOllama(
    model="openai/gpt-oss-20b",
    temperature=0.7,
    model_kwargs={"reasoning_effort": "high"}  # ~4-6s
)
```

#### Ventajas vs Alternativas

| CaracterÃ­stica | GPT-OSS 20B | Llama 3.1 70B | Claude API |
|----------------|-------------|---------------|------------|
| **Function calling** | â­â­â­â­â­ OpenAI | â­â­â­â­ Bueno | â­â­â­â­â­ Excelente |
| **VRAM requerida** | 16GB | 40GB | 0GB |
| **Velocidad** | 2-3s | 5-8s | 1-2s |
| **Costo** | $0/mes | $0/mes | $10-30/mes |
| **Razonamiento** | â­â­â­â­ o3-mini | â­â­â­â­â­ | â­â­â­â­â­ |
| **Cabe RTX 5090** | âœ… Perfecto | âš ï¸ Offloading | âœ… API |
| **Structured out** | âœ… Nativo | âš ï¸ Limitado | âœ… Nativo |
| **Privacidad** | âœ… 100% local | âœ… 100% local | âŒ Cloud |

#### Requisitos de Hardware

```
GPU: NVIDIA RTX 5090 (24GB VRAM) âœ“ DISPONIBLE
VRAM usada: 16GB modelo + 2GB buffer
RAM: 32GB recomendada
Disco: 20GB para modelo cuantizado
CPU: MÃ­nimo 8 cores (preprocesamiento)

ConfiguraciÃ³n Ã³ptima:
- RTX 5090: 24GB VRAM â†’ 8GB libres
- CuantizaciÃ³n: Q4 (nativo en Ollama)
- Offloading: No necesario
```

#### InstalaciÃ³n

```bash
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Descargar GPT-OSS 20B (~12GB, toma 15min)
ollama pull openai/gpt-oss-20b

# Verificar
ollama run openai/gpt-oss-20b "Eres InfraGuardian AI"

# Autostart
sudo systemctl enable ollama
sudo systemctl start ollama
```

#### IntegraciÃ³n con LangChain

```python
from langchain_ollama import ChatOllama
from langchain.tools import tool

# Inicializar LLM
llm = ChatOllama(
    model="openai/gpt-oss-20b",
    base_url="http://localhost:11434",
    temperature=0.5
)

# Definir herramientas
@tool
def restart_service(compose_id: str) -> str:
    """Reinicia servicio Docker Compose vÃ­a Dokploy"""
    # ImplementaciÃ³n...
    return f"Service restarted"

# Agent con tools
from langgraph.prebuilt import create_react_agent

agent = create_react_agent(
    llm,
    tools=[restart_service, get_logs]
)
```

---

## ğŸ§© Componentes Principales

### 1. Dokploy-Aware Agent

**Archivo:** `src/agent/dokploy_agent.py`

```python
from langgraph.graph import StateGraph
from langchain_ollama import ChatOllama

class DokployAgentState(TypedDict):
    """Estado del agente con contexto Dokploy"""
    # Contexto del problema
    incident_type: str              # "container_down", "high_cpu", etc.
    project_id: Optional[str]
    compose_id: Optional[str]
    service_name: Optional[str]

    # Datos recopilados
    compose_services: List[Dict]    # Servicios del compose
    container_stats: Dict           # MÃ©tricas Docker
    logs: str                       # Logs del container
    deployment_history: List[Dict]  # Historial de deploys

    # AnÃ¡lisis
    root_cause: Optional[str]       # Causa raÃ­z identificada
    affected_services: List[str]    # Servicios afectados
    solution_plan: Optional[Dict]   # Plan de soluciÃ³n

    # EjecuciÃ³n
    actions_taken: List[Dict]       # Acciones ejecutadas
    result: Optional[str]           # Resultado final


def create_dokploy_agent():
    """Crea el agente LangGraph especializado en Dokploy"""

    workflow = StateGraph(DokployAgentState)

    # Nodos
    workflow.add_node("detect_incident", detect_incident_node)
    workflow.add_node("gather_context", gather_dokploy_context)
    workflow.add_node("analyze_compose", analyze_compose_dependencies)
    workflow.add_node("diagnose", diagnose_with_llm)
    workflow.add_node("plan_solution", plan_dokploy_solution)
    workflow.add_node("execute_action", execute_via_dokploy)
    workflow.add_node("verify_fix", verify_health_checks)
    workflow.add_node("rollback", rollback_deployment)
    workflow.add_node("escalate", escalate_to_human)

    # Flujo
    workflow.set_entry_point("detect_incident")

    workflow.add_edge("detect_incident", "gather_context")
    workflow.add_edge("gather_context", "analyze_compose")
    workflow.add_edge("analyze_compose", "diagnose")

    workflow.add_conditional_edges(
        "diagnose",
        should_auto_fix,
        {
            "auto": "plan_solution",
            "manual": "escalate"
        }
    )

    workflow.add_edge("plan_solution", "execute_action")

    workflow.add_conditional_edges(
        "execute_action",
        check_execution_success,
        {
            "success": "verify_fix",
            "failure": "rollback"
        }
    )

    workflow.add_conditional_edges(
        "verify_fix",
        check_health,
        {
            "healthy": END,
            "unhealthy": "rollback",
            "unknown": "escalate"
        }
    )

    workflow.add_edge("rollback", "escalate")

    return workflow.compile()
```

### 2. Runbooks EspecÃ­ficos Dokploy

**Archivo:** `runbooks/compose_service_down.yaml`

```yaml
name: "Docker Compose Service Down"
description: "Servicio de un compose ha caÃ­do"

trigger:
  event: "container_unhealthy"
  scope: "docker_compose"

context_gathering:
  - action: "get_compose_info"
    tool: "dokploy.compose.one"
    params:
      composeId: "${incident.compose_id}"

  - action: "get_all_services"
    tool: "dokploy.compose.loadServices"
    params:
      composeId: "${incident.compose_id}"

  - action: "get_container_logs"
    tool: "docker.get_logs"
    params:
      container_id: "${incident.container_id}"
      tail: 1000

  - action: "get_deployment_history"
    tool: "dokploy.deployment.allByCompose"
    params:
      composeId: "${incident.compose_id}"

diagnosis:
  llm_prompt: |
    Analiza el siguiente escenario:

    Servicio caÃ­do: ${incident.service_name}
    Project: ${context.compose_info.name}
    Compose ID: ${incident.compose_id}

    Servicios en el compose:
    ${context.all_services}

    Ãšltimos logs (1000 lÃ­neas):
    ${context.container_logs}

    Ãšltimo deployment:
    ${context.deployment_history[0]}

    DiagnÃ³stico:
    1. Â¿QuÃ© causÃ³ la caÃ­da?
    2. Â¿Hay servicios dependientes afectados?
    3. Â¿Es problema de cÃ³digo o infraestructura?
    4. Â¿El Ãºltimo deploy introdujo el problema?

solutions:
  - name: "Restart via Dokploy"
    confidence_threshold: 0.9
    conditions:
      - error_type: "transient"
      - no_code_changes_needed: true

    actions:
      - tool: "dokploy.compose.start"
        params:
          composeId: "${incident.compose_id}"
        retry: 2
        wait_seconds: 10

      - tool: "verify_health"
        params:
          service_name: "${incident.service_name}"
        timeout: 60

  - name: "Redeploy Compose"
    confidence_threshold: 0.8
    conditions:
      - error_type: "deployment_issue"
      - config_changed: true

    actions:
      - tool: "dokploy.compose.redeploy"
        params:
          composeId: "${incident.compose_id}"
        wait_for_completion: true

      - tool: "verify_all_services"
        params:
          composeId: "${incident.compose_id}"

  - name: "Rollback to Previous Deployment"
    confidence_threshold: 0.7
    conditions:
      - recent_deployment: true
      - error_after_deploy: true
      - previous_deployment_successful: true

    actions:
      - tool: "get_previous_successful_deployment"
        params:
          composeId: "${incident.compose_id}"

      - tool: "dokploy.compose.deploy"
        params:
          composeId: "${incident.compose_id}"
          commitHash: "${previous_deployment.commit}"
        note: "Rollback automÃ¡tico al commit ${previous_deployment.commit}"

escalation:
  triggers:
    - all_solutions_failed: true
    - confidence_below: 0.6
    - critical_service: true

  notification:
    telegram:
      message: |
        âš ï¸ Escalamiento requerido

        Servicio: ${incident.service_name}
        Proyecto: ${context.compose_info.name}

        Problema detectado:
        ${diagnosis.root_cause}

        Soluciones intentadas:
        ${actions_taken}

        Se requiere intervenciÃ³n manual.

        [Ver Logs] [Ver Compose] [Historial]
```

### 3. Herramientas Dokploy

**Archivo:** `src/tools/dokploy_tools.py`

```python
from langchain.tools import tool
from typing import Optional, List, Dict

@tool
def get_project_info(project_id: str) -> Dict:
    """
    Obtiene informaciÃ³n completa de un proyecto Dokploy.

    Args:
        project_id: ID del proyecto

    Returns:
        InformaciÃ³n del proyecto incluyendo todos sus composes,
        bases de datos, y environments
    """
    client = DokployClient()
    return await client.get_project(project_id)


@tool
def get_compose_services(compose_id: str) -> List[Dict]:
    """
    Lista todos los servicios de un Docker Compose.

    Args:
        compose_id: ID del compose en Dokploy

    Returns:
        Lista de servicios con su configuraciÃ³n
    """
    client = DokployClient()
    return await client.get_compose_services(compose_id)


@tool
def restart_compose_service(
    compose_id: str,
    service_name: Optional[str] = None
) -> Dict:
    """
    Reinicia un servicio especÃ­fico o todo el compose.

    Args:
        compose_id: ID del compose
        service_name: Nombre del servicio (opcional, si None reinicia todo)

    Returns:
        Estado de la operaciÃ³n
    """
    if service_name:
        # Restart especÃ­fico vÃ­a Docker API
        docker_client = docker.from_env()
        container = docker_client.containers.get(
            f"{compose_name}-{service_name}"
        )
        container.restart()
        return {"status": "restarted", "service": service_name}
    else:
        # Restart todo el compose vÃ­a Dokploy
        client = DokployClient()
        await client.compose_stop(compose_id)
        await asyncio.sleep(5)
        await client.compose_start(compose_id)
        return {"status": "restarted", "compose_id": compose_id}


@tool
def deploy_compose(compose_id: str) -> Dict:
    """
    Deploya o redeploya un compose completo.

    Args:
        compose_id: ID del compose

    Returns:
        Estado del deployment
    """
    client = DokployClient()
    result = await client.compose_deploy(compose_id)

    # Esperar a que termine el deployment
    deployment_id = result["deploymentId"]
    status = await wait_for_deployment(deployment_id)

    return {
        "deployment_id": deployment_id,
        "status": status,
        "success": status == "done"
    }


@tool
def get_compose_logs(compose_id: str, service_name: str, tail: int = 1000) -> str:
    """
    Obtiene los logs de un servicio del compose.

    Args:
        compose_id: ID del compose
        service_name: Nombre del servicio
        tail: NÃºmero de lÃ­neas a obtener

    Returns:
        Logs del servicio
    """
    # Primero obtener el nombre del proyecto
    client = DokployClient()
    compose_info = await client.compose_one(compose_id)
    project_name = compose_info["appName"]

    # Obtener container vÃ­a Docker
    docker_client = docker.from_env()
    containers = docker_client.containers.list(
        filters={
            "label": f"com.docker.compose.project={project_name}",
            "label": f"com.docker.compose.service={service_name}"
        }
    )

    if not containers:
        return f"No container found for service {service_name}"

    container = containers[0]
    logs = container.logs(tail=tail, timestamps=True)
    return logs.decode('utf-8')


@tool
def analyze_compose_health(compose_id: str) -> Dict:
    """
    Analiza el health de todos los servicios de un compose.

    Args:
        compose_id: ID del compose

    Returns:
        Estado de salud de cada servicio
    """
    client = DokployClient()
    compose_info = await client.compose_one(compose_id)
    services = await client.get_compose_services(compose_id)

    project_name = compose_info["appName"]

    # Analizar cada servicio
    docker_client = docker.from_env()
    health_report = {}

    for service in services:
        service_name = service["name"]

        containers = docker_client.containers.list(
            all=True,
            filters={
                "label": f"com.docker.compose.project={project_name}",
                "label": f"com.docker.compose.service={service_name}"
            }
        )

        if not containers:
            health_report[service_name] = {
                "status": "not_found",
                "healthy": False
            }
            continue

        container = containers[0]
        stats = container.stats(stream=False)

        health_report[service_name] = {
            "status": container.status,
            "healthy": container.status == "running",
            "cpu_percent": calculate_cpu_percent(stats),
            "memory_mb": stats["memory_stats"]["usage"] / 1024 / 1024,
            "restart_count": container.attrs["RestartCount"]
        }

    return health_report


@tool
def rollback_compose_deployment(compose_id: str) -> Dict:
    """
    Rollback al deployment anterior exitoso.

    Args:
        compose_id: ID del compose

    Returns:
        Estado del rollback
    """
    client = DokployClient()

    # Obtener historial
    deployments = await client.get_deployment_history(compose_id)

    # Buscar Ãºltimo deployment exitoso anterior al actual
    successful_deployments = [
        d for d in deployments
        if d["status"] == "done" and d != deployments[0]
    ]

    if not successful_deployments:
        return {
            "success": False,
            "error": "No previous successful deployment found"
        }

    previous = successful_deployments[0]

    # Trigger redeploy con ese commit
    # Nota: Dokploy no tiene endpoint directo de rollback,
    # pero podemos hacer checkout del commit anterior y redeploy
    result = await client.compose_redeploy(compose_id)

    return {
        "success": True,
        "rolled_back_to": previous["createdAt"],
        "deployment_id": result["deploymentId"]
    }
```

---

## ğŸ’¼ Casos de Uso Dokploy EspecÃ­ficos

### Caso 1: Granada Shariff - API No Responde

**Escenario Real:**
El servicio `api` del proyecto Granada Shariff devuelve 502.

```
[02:15:00] ğŸ”´ DETECCIÃ“N
  Uptime Kuma: granada.back.sphyrnasolutions.com â†’ HTTP 502
  Domain ID: I4WmjE5TdAWBLF4RGFOcY
  â†“
[02:15:05] ğŸ” CONTEXTO
  Agente obtiene vÃ­a Dokploy API:
  - Project: Granada Shariff (sNXBbGQT2Ic9V6qXVlhUu)
  - Compose: dashboard (56SmVbZnH2IMcA4fQHLUw)
  - Services: frontend, api, postgres, redis, celery

  Estado Docker:
  - frontend: âœ“ running
  - api: âœ— restarting (exit code 137 - OOM killed)
  - postgres: âœ“ running
  - redis: âœ“ running
  - celery: âš  degraded (waiting for api)
  â†“
[02:15:15] ğŸ§  ANÃLISIS LLM
  Claude analiza:
  "El servicio API fue killed por OOM (Out of Memory).
   Exit code 137 indica que el kernel matÃ³ el proceso.

   Ãšltimos logs muestran:
   - Memory usage creciÃ³ gradualmente
   - Ãšltima operaciÃ³n: bulk insert de 500k registros
   - No hay memory leaks en cÃ³digo reciente

   Causa raÃ­z: LÃ­mite de memoria muy bajo (2GB)
   vs operaciÃ³n legÃ­tima que requiere mÃ¡s.

   Servicios afectados:
   - API (down)
   - Celery (degraded, esperando API)
   - Frontend (partial, cachea algunas requests)

   SoluciÃ³n: Aumentar memoria + reiniciar"
  â†“
[02:15:30] ğŸ’¡ PLAN
  Runbook: compose_service_oom.yaml
  Confianza: 92%

  Plan:
  1. Actualizar memory limit: 2GB â†’ 4GB
  2. Restart servicio API
  3. Verificar celery se recupera
  4. Monitorear memory usage siguiente hora
  â†“
[02:15:40] ğŸ”§ EJECUCIÃ“N
  1. Agente actualiza docker-compose.yml vÃ­a Dokploy:
     services:
       api:
         deploy:
           resources:
             limits:
               memory: 4G  # era 2G

  2. Trigger redeploy vÃ­a Dokploy API:
     POST /compose.redeploy
     { "composeId": "56SmVbZnH2IMcA4fQHLUw" }

  3. Espera deployment complete (90 segundos)
  â†“
[02:17:15] âœ… VERIFICACIÃ“N
  Health checks:
  - api: âœ“ running, memory: 1.2GB/4GB
  - celery: âœ“ running, processing jobs
  - frontend: âœ“ all requests succeeding

  Domain check:
  - granada.back.sphyrnasolutions.com â†’ HTTP 200 âœ“
  â†“
[02:17:20] ğŸ“± NOTIFICACIÃ“N
  Telegram:
  "âœ… Incidente resuelto - Granada Shariff API

   ğŸ”´ Problema:
   API caÃ­da por OOM (memoria insuficiente)

   ğŸ”§ SoluciÃ³n aplicada:
   â€¢ Memory limit aumentado: 2GB â†’ 4GB
   â€¢ Servicio redeployado
   â€¢ Tiempo de resoluciÃ³n: 2min 20s

   ğŸ“Š Estado actual:
   â€¢ API: âœ“ Healthy (1.2GB/4GB)
   â€¢ Celery: âœ“ Processing
   â€¢ Frontend: âœ“ All requests OK

   ğŸ’¡ RecomendaciÃ³n:
   Investigar el bulk insert de 500k registros.
   Considerar paginaciÃ³n o procesamiento por lotes.

   [Ver Logs] [MÃ©tricas]"
  â†“
[02:17:30] ğŸ“š APRENDIZAJE
  Agente actualiza knowledge base:

  Pattern registrado:
  - Service: API (FastAPI)
  - Symptom: Exit code 137 + restarting loop
  - Root cause: OOM durante bulk operations
  - Solution: Increase memory + code optimization

  Runbook actualizado:
  - Threshold de alerta: >80% memory durante >5min
  - Auto-scale memory si disponible
  - Notificar sobre bulk operations sin pagination
```

### Caso 2: SaaS RAG - Weaviate Lento

**Escenario Real:**
Weaviate (vector DB) respondiendo muy lento, afectando queries del RAG.

```
[14:30:00] ğŸŸ¡ DETECCIÃ“N
  Custom metrics: Weaviate query time > 5s (threshold: 500ms)
  â†“
[14:30:05] ğŸ” CONTEXTO DOKPLOY
  Project: Saas Rag (aW_XGVs4XOe-qkNLqU_c8)
  Compose: Backend (B83szPTH3c6YER7-XcZ3_)

  Servicios:
  - saas-rag-fastapi (depende de weaviate)
  - saas-rag-postgres
  - saas-rag-redis
  - saas-rag-mongodb
  - saas-rag-weaviate â† Problema aquÃ­

  Docker stats weaviate:
  - CPU: 95% (spike inusual)
  - Memory: 2.1GB/4GB
  - Disk I/O: Alto (writes continuas)
  â†“
[14:30:15] ğŸ“Š ANÃLISIS COMPOSE
  Agente analiza docker-compose.yml:

  services:
    saas-rag-weaviate:
      image: weaviate
      environment:
        PERSISTENCE_DATA_PATH: /var/lib/weaviate
      volumes:
        - weaviate_data:/var/lib/weaviate

  Agente check volumen:
  - Size: 18GB/20GB (90% usado)
  - Inodes: 95% usado

  Logs weaviate:
  "WARN: Compaction running, high disk usage detected"
  "INFO: Running background maintenance"
  â†“
[14:30:30] ğŸ§  DIAGNÃ“STICO LLM
  "Weaviate estÃ¡ ejecutando compaction automÃ¡tica porque
   el disco estÃ¡ casi lleno. Este es un proceso intensivo
   que bloquea queries.

   Causa raÃ­z: Volumen de datos creciendo sin cleanup.

   No es un problema crÃ­tico, es mantenimiento necesario.
   PERO podemos optimizarlo:

   1. Aumentar tamaÃ±o de volumen (20GB â†’ 50GB)
   2. Configurar cleanup automÃ¡tico de vectores antiguos
   3. Dejar que compaction termine naturalmente

   Riesgo: BAJO (es mantenimiento normal)
   Urgencia: MEDIA (afecta performance pero no disponibilidad)"
  â†“
[14:30:45] ğŸ¤” DECISIÃ“N
  Confianza: 75% (no 100% por ser cambio de volumen)

  Agente decide: Pedir aprobaciÃ³n para cambios,
  pero puede optimizar configuraciÃ³n ya.
  â†“
[14:31:00] ğŸ“± NOTIFICACIÃ“N + ACCIÃ“N
  Telegram:
  "âš ï¸ Weaviate lento - Mantenimiento en curso

   Weaviate estÃ¡ ejecutando compaction automÃ¡tica.
   Esto es normal pero estÃ¡ causando lentitud.

   ğŸ“Š Estado:
   â€¢ Volumen: 18GB/20GB (90% usado)
   â€¢ CPU: 95% (compaction)
   â€¢ Query time: 5s (normal: 500ms)

   ğŸ’¡ Puedo hacer:
   1. âœ… Optimizar config de compaction (YA HECHO)
   2. â³ Aumentar volumen 20GBâ†’50GB (NECESITA APROBACIÃ“N)
   3. â³ Configurar cleanup automÃ¡tico (NECESITA APROBACIÃ“N)

   La compaction terminarÃ¡ en ~15min. Â¿Proceder con #2 y #3?

   [âœ… SÃ­] [âŒ No] [â¸ Esperar]"

  Mientras tanto, agente ya optimizÃ³:
  - AjustÃ³ HNSW_EF para mejor performance durante compaction
  - ConfigurÃ³ batch_size menor para reducir memory spikes
  â†“
[14:35:00] ğŸ‘¤ USUARIO APRUEBA
  â†“
[14:35:10] ğŸ”§ EJECUCIÃ“N
  1. Agente actualiza docker-compose.yml:
     volumes:
       weaviate_data:
         driver: local
         driver_opts:
           type: none
           device: /mnt/weaviate-large  # Nuevo volumen 50GB
           o: bind

  2. Agente crea script de migraciÃ³n:
     - Stop weaviate
     - Rsync data a nuevo volumen
     - Update compose
     - Redeploy

  3. Ejecuta vÃ­a Dokploy:
     POST /compose.update  # Actualizar compose
     POST /compose.redeploy  # Redeploy con nuevo volumen
  â†“
[14:42:00] âœ… COMPLETADO
  Telegram:
  "âœ… Weaviate optimizado

   âœ“ Compaction completada naturalmente
   âœ“ Volumen migrado: 20GB â†’ 50GB
   âœ“ Config optimizada para auto-cleanup

   ğŸ“Š Resultado:
   â€¢ Query time: 5s â†’ 180ms âœ“
   â€¢ CPU: 95% â†’ 12%
   â€¢ Disk usage: 90% â†’ 36%

   ğŸ¯ PrÃ³ximos pasos automÃ¡ticos:
   â€¢ Cleanup de vectores >90 dÃ­as (semanal)
   â€¢ Alerta si disco >70%
   â€¢ OptimizaciÃ³n de Ã­ndices (mensual)"
```

### Caso 3: N8N - Workflow Bloqueado

**Escenario:**
N8N workflow stuck, no procesa nuevas ejecuciones.

```
[09:00:00] ğŸ”´ DETECCIÃ“N
  Custom monitor: N8N queue depth = 45 (threshold: 10)
  Ãšltima ejecuciÃ³n completada: hace 2 horas
  â†“
[09:00:05] ğŸ” ANÃLISIS DOKPLOY
  Project: Random_Test (5oFz33_YIUBsd8itqRgvu)
  Compose: n8n (NYEI7PjWArBVZcFMs2hU0)

  Servicio: n8n (isolated deployment)

  Docker stats:
  - Status: running
  - CPU: 0.1% (sospechosamente bajo)
  - Memory: 890MB/1GB
  - No errors en health check

  Logs N8N:
  "Workflow 'daily-backup' execution started"
  "Connecting to S3..."
  [Silence durante 2 horas]
  â†“
[09:00:20] ğŸ§  DIAGNÃ“STICO
  Agente analiza:
  "N8N estÃ¡ stuck en una operaciÃ³n de S3.
   Probablemente timeout o deadlock en el workflow.

   Opciones:
   1. Restart container (pierde ejecuciÃ³n actual)
   2. Exec into container y kill proceso especÃ­fico
   3. Esperar timeout (si estÃ¡ configurado)

   Dado que han pasado 2 horas y threshold es 30min,
   restart es la mejor opciÃ³n."

  Confianza: 88%
  â†“
[09:00:30] ğŸ”§ AUTO-FIX
  AcciÃ³n: Restart container N8N

  vÃ­a Docker API (mÃ¡s rÃ¡pido que redeploy):
  docker.containers.get("randomtest-n8n").restart()
  â†“
[09:00:45] âœ… VERIFICACIÃ“N
  - Container: âœ“ running
  - N8N responsive: âœ“
  - Queue processing: âœ“ 45 â†’ 0 en 2min

  InvestigaciÃ³n post-mortem automÃ¡tica:
  - Check workflow 'daily-backup'
  - Encuentra: S3 endpoint cambiÃ³ (configuraciÃ³n)
  â†“
[09:03:00] ğŸ“± NOTIFICACIÃ“N
  Telegram:
  "âœ… N8N desbloqueado

   El workflow 'daily-backup' estaba stuck
   esperando S3 que no respondÃ­a.

   ğŸ”§ AcciÃ³n: Container restart
   ğŸ“Š Resultado: 45 workflows procesados

   âš ï¸ Problema encontrado:
   S3 endpoint en workflow estÃ¡ desactualizado.

   Â¿Quieres que actualice el workflow automÃ¡ticamente?
   Nuevo endpoint: https://s3.sphyrnasolutions.com

   [âœ… Actualizar] [âŒ Revisar manual]"
```

---

## ğŸ“… Plan de ImplementaciÃ³n Optimizado

### Fase 1: Core Dokploy (Semana 1-2)

#### Sprint 1.1: Dokploy Client (3 dÃ­as)

```python
Entregables:
âœ“ DokployClient con 30+ mÃ©todos
âœ“ Tests de integraciÃ³n con API real
âœ“ Error handling robusto
âœ“ Async/await optimizado

Tareas:
1. Implementar cliente HTTP para Dokploy API
2. MÃ©todos para compose (deploy, start, stop, etc.)
3. MÃ©todos para projects, domains, deployments
4. Rate limiting y retry logic
5. Tests unitarios + integraciÃ³n
```

#### Sprint 1.2: Docker Integration (4 dÃ­as)

```python
Entregables:
âœ“ Docker client wrapper
âœ“ Compose analyzer (parse docker-compose.yml)
âœ“ Container health checker
âœ“ Log aggregator
âœ“ Stats collector

Tareas:
1. Docker SDK integration
2. Parse de docker-compose.yml (dependencies)
3. Health check monitor
4. Log streaming desde containers
5. Metrics collection (CPU, RAM, Network)
```

### Fase 2: Agent Intelligence (Semana 3-4)

#### Sprint 2.1: LangGraph Agent (5 dÃ­as)

```python
Entregables:
âœ“ DokployAgentState definido
âœ“ StateGraph con 8 nodos
âœ“ 3 runbooks bÃ¡sicos funcionando
âœ“ Claude integration

Tareas:
1. Definir DokployAgentState (TypedDict)
2. Crear StateGraph con flujo completo
3. Implementar nodos: detect, analyze, plan, execute, verify
4. Integrar Claude Sonnet
5. Runbooks: service_down, high_memory, deployment_failed
```

#### Sprint 2.2: Knowledge Base (5 dÃ­as)

```python
Entregables:
âœ“ ChromaDB setup
âœ“ Incident memory (embeddings)
âœ“ 10 runbooks Dokploy
âœ“ Compose pattern recognition

Tareas:
1. Setup ChromaDB local
2. Embeddings de incidentes pasados
3. 10 runbooks completos (YAML)
4. Sistema de bÃºsqueda semÃ¡ntica
5. Compose dependency analyzer
```

### Fase 3: Interfaces (Semana 5)

#### Sprint 3.1: Telegram Bot (4 dÃ­as)

```python
Entregables:
âœ“ Bot 24/7 funcional
âœ“ 15 comandos
âœ“ ConversaciÃ³n natural
âœ“ Notificaciones rich

Comandos:
/status [project]       - Estado general o de proyecto
/services [compose]     - Listar servicios de compose
/logs <service> [n]     - Ver logs (Ãºltimas n lÃ­neas)
/restart <service>      - Reiniciar servicio
/deploy <compose>       - Deploy/redeploy
/rollback <compose>     - Rollback a deploy anterior
/health <compose>       - Health de todos los servicios
/metrics <service>      - CPU/RAM/Network
/incidents [n]          - Ãšltimos n incidentes
/approve <incident>     - Aprobar acciÃ³n propuesta
/help                   - Ayuda

Conversacional:
"Â¿Por quÃ© estÃ¡ caÃ­do Granada?"
"MuÃ©strame los logs del API de RAG"
"Reinicia el Weaviate"
"Â¿CuÃ¡nto CPU usa el frontend?"
```

#### Sprint 3.2: Dashboard (3 dÃ­as)

```python
Entregables:
âœ“ Next.js dashboard
âœ“ Vista de projects/composes
âœ“ Timeline de incidentes
âœ“ MÃ©tricas en tiempo real

PÃ¡ginas:
- /              # Overview de todos los projects
- /projects/:id  # Detalle de project con composes
- /composes/:id  # Servicios del compose + mÃ©tricas
- /incidents     # Timeline de incidentes
- /agent         # Estado del agente
```

### Fase 4: Testing & Deploy (Semana 6)

#### Sprint 4.1: Testing Completo (3 dÃ­as)

```python
Entregables:
âœ“ Tests unitarios (80%+ coverage)
âœ“ Tests de integraciÃ³n
âœ“ Tests end-to-end

Tests crÃ­ticos:
- Restart service â†’ Verifica que sube
- Deploy compose â†’ Verifica health checks
- Rollback â†’ Verifica deployment anterior
- Agent flow completo (detectâ†’fixâ†’verify)
```

#### Sprint 4.2: Production Deploy (4 dÃ­as)

```python
Entregables:
âœ“ Agente deployado en Dokploy (ironÃ­a!)
âœ“ CI/CD configurado
âœ“ Monitoring del agente mismo
âœ“ DocumentaciÃ³n completa

Deploy:
El agente mismo serÃ¡ un compose en Dokploy:

services:
  infraguardian-agent:
    build: .
    environment:
      - DOKPLOY_API_KEY=${API_KEY}
      - CLAUDE_API_KEY=${CLAUDE_KEY}
      - TELEGRAM_BOT_TOKEN=${BOT_TOKEN}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./knowledge:/app/knowledge

  infraguardian-db:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data

  infraguardian-redis:
    image: redis:7

  infraguardian-chromadb:
    image: chromadb/chroma:latest
    volumes:
      - chroma_data:/chroma/chroma
```

---

## ğŸ’° Estimaciones Actualizadas

### Desarrollo

```
Fase 1: Dokploy Integration     2 semanas
Fase 2: Agent Intelligence       2 semanas
Fase 3: Interfaces               1 semana
Fase 4: Testing & Deploy         1 semana
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                            6 semanas
```

### Costos Operacionales

```
LLM (GPT-OSS 20B):
  - Modelo: 100% local en RTX 5090
  - VRAM requerida: 16GB (Q4 cuantizado)
  - Costo API: $0/mes
  - Latencia: ~2-3s por respuesta
  - Sin lÃ­mites de tokens
  Total: $0/mes

Infraestructura:
  - Servidor: $0 (ya existe, Dokploy)
  - GPU: $0 (ya existe, RTX 5090)
  - Docker resources:
    - CPU: 0.5 core
    - RAM: 2GB
    - Disk: 20GB (modelo + datos)
  - PostgreSQL: $0 (containerizado)
  - Redis: $0 (containerizado)
  - ChromaDB: $0 (local)

Telegram: $0 (gratuito)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: $0/mes ğŸ‰
```

### ROI

```
Ahorro de tiempo actual:
  - Incidentes/mes Dokploy: ~15
  - Tiempo promedio resoluciÃ³n: 45min
  - Total: 11.25 horas/mes

Con InfraGuardian:
  - Auto-resoluciÃ³n: 85% (12 incidentes)
  - Tiempo auto: 3min promedio
  - Manual asistido: 15% (3 incidentes)
  - Tiempo asistido: 20min

  Tiempo total: (12 Ã— 3min) + (3 Ã— 20min) = 96min

Ahorro: 11.25h - 1.6h = 9.65 horas/mes

Valor: 9.65h Ã— $50/h = $482.50/mes
Costo: $0/mes (100% local)

ROI: INFINITO âˆ (sin costos recurrentes)
```

---

## ğŸš€ PrÃ³ximos Pasos

### Comenzar HOY

```bash
# 1. Crear proyecto
mkdir infraguardian-dokploy
cd infraguardian-dokploy

# 2. Estructura
mkdir -p src/{agent,tools,integrations,interfaces,knowledge}
mkdir -p runbooks tests config

# 3. Setup Python
python3.11 -m venv venv
source venv/bin/activate

# 4. Instalar dependencias base
pip install \
  langchain==0.1.5 \
  langgraph==0.0.20 \
  langchain-anthropic==0.0.2 \
  docker==7.0.0 \
  python-telegram-bot==20.7 \
  chromadb==0.4.22 \
  fastapi==0.109.0

# 5. Instalar y configurar Ollama + GPT-OSS 20B
curl -fsSL https://ollama.com/install.sh | sh
ollama pull openai/gpt-oss-20b

# Test rÃ¡pido del modelo
ollama run openai/gpt-oss-20b "Analiza este error de Docker: 'Exit code 137'. Â¿QuÃ© significa?"
# Debe responder sobre OOM (Out of Memory)

# 6. Configurar .env
cat > .env << EOF
DOKPLOY_API_URL=https://settings.sphyrnasolutions.com/api
DOKPLOY_API_KEY=claude_mcplpIwzCRCcOdvOmdtYcFNaBrzkdtJSoZIdtJvPhfmWhdBSRQNcijXVemATQXlRPHb
OLLAMA_MODEL=openai/gpt-oss-20b
OLLAMA_BASE_URL=http://localhost:11434
TELEGRAM_BOT_TOKEN=tu_bot_token
EOF

# 7. Primera prueba: Dokploy Client
cat > src/integrations/dokploy_client.py << 'EOF'
import aiohttp
import os

class DokployClient:
    def __init__(self):
        self.base_url = os.getenv("DOKPLOY_API_URL")
        self.api_key = os.getenv("DOKPLOY_API_KEY")

    async def get_all_projects(self):
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{self.base_url}/project.all",
                headers={"x-api-key": self.api_key}
            ) as response:
                return await response.json()

# Test
if __name__ == "__main__":
    import asyncio
    client = DokployClient()
    projects = asyncio.run(client.get_all_projects())
    print(f"Found {len(projects)} projects")
    for p in projects:
        print(f"  - {p['name']}")
EOF

# 8. Ejecutar test
python src/integrations/dokploy_client.py
```

### Primer Milestone (Semana 1)

**Objetivo:** Cliente Dokploy funcional + Docker integration

```python
# Al final de la semana 1 deberÃ­as tener:

# 1. Dokploy Client completo
client = DokployClient()
projects = await client.get_all_projects()
composes = await client.get_compose_services(compose_id)
await client.restart_compose(compose_id)

# 2. Docker integration
docker_client = DockerClient()
containers = docker_client.get_compose_containers("granada-shariff")
logs = docker_client.get_logs(container_id, tail=100)
stats = docker_client.get_stats(container_id)

# 3. Primer runbook funcionando
# runbooks/compose_service_down.yaml ejecutÃ¡ndose
```

---

## ğŸ“š Recursos EspecÃ­ficos Dokploy

### DocumentaciÃ³n

- **Dokploy API OpenAPI**: https://settings.sphyrnasolutions.com/swagger
- **Tu OpenAPI Document**: `/tmp/dokploy-openapi.json` (ya descargado)
- **Docker Compose Reference**: https://docs.docker.com/compose/
- **Docker Python SDK**: https://docker-py.readthedocs.io/

### Ejemplos de Compose

Puedes acceder a tus propios docker-compose.yml vÃ­a Dokploy API:

```python
# Ver compose de Granada
compose_info = await client.compose_one("56SmVbZnH2IMcA4fQHLUw")
compose_file = compose_info["composeFile"]

# Ahora el agente puede parsear y entender:
import yaml
compose_data = yaml.safe_load(compose_file)
services = compose_data["services"]
# Analizar dependencies, volumes, networks, etc.
```

---

## ğŸ¯ ConclusiÃ³n

**InfraGuardian AI - Dokploy Edition** estÃ¡ diseÃ±ado especÃ­ficamente para tu stack:

âœ… **100% Dokploy-native**: Usa exclusivamente Dokploy API
âœ… **Compose-aware**: Entiende relaciones entre servicios
âœ… **Docker-optimized**: Aprovecha Docker API para detalles
âœ… **Simple deployment**: El agente mismo corre en Dokploy
âœ… **100% Gratuito**: $0/mes (GPT-OSS 20B local en RTX 5090)
âœ… **Privacidad total**: Todo corre en tu servidor, cero datos a terceros
âœ… **Fast to build**: 6 semanas vs 8-10 de versiÃ³n genÃ©rica

**Siguiente acciÃ³n:**
Ejecuta los comandos de "Comenzar HOY" y tendrÃ¡s el proyecto base funcionando en 30 minutos.

Â¿Empezamos? ğŸš€
